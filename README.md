# âœŠğŸ–ï¸âœŒï¸ Rock-Paper-Scissors App (AI gesture classifier)
- Rock-Paper-Scissor is a machine learningâ€“powered web app that recognizes hand gestures in images, predicts whether they represent rock, paper, or scissors and lets user play against the machine.

- Originally built with a FastAPI backend for inference and fully Dockerized for local deployment, the project has since been streamlined and deployed on Hugging Face Spaces using Streamlit â€” simplifying hosting, reducing infrastructure overhead, and making the app instantly accessible online.


---
## ğŸš€ Features

ğŸ§  Deep Learning Classification â€“ EfficientNet-based model trained for robust gesture recognition
 
ğŸ“¸ Interactive Web Interface â€“ Upload an image and play against the computer in real time

âš™ï¸ Hugging Face Deployment â€“ Zero-setup web access and continuous availability

ğŸ³ Dockerized Environment â€“ Reproducible local setup and flexible deployment


---
## ğŸ§© Repository Structure

â€¢ This project is organized with the following structure to match Hugging Face requirements:

```bash
    â”œâ”€â”€ rock-paper-scissor_app    /      
    â”‚   â”œâ”€â”€ app.py                       # Frontend entry point                 
    â”‚   â”œâ”€â”€ Dockerfile                   # Backend Dockerfile
    â”‚   â””â”€â”€ models/                      # Trained model
    â”‚       â””â”€â”€ best_model.keras
    â”‚   â”œâ”€â”€ requirements.txt
    â”‚   â””â”€â”€ rock_paper_scissor/          # Core logic: model loading & utils
    â”‚       â””â”€â”€ model.pyr
    â”‚       â””â”€â”€ utils
    â”‚           â””â”€â”€ logging_utils.py
```

---
## ğŸ§  Technical Overview

### ğŸ“‚ Dataset

- Based on an open [Kaggle dataset](https://www.kaggle.com/datasets/drgfreeman/rockpaperscissors) of hand gesture images for Rock, Paper, Scissors.

- Images were resized and augmented to improve generalization.


### ğŸ¤– Model

- Built using Keras / TensorFlow with EfficientNet as the base.

- Trained to classify three gesture categories: rock, paper, scissors

- Achieved strong accuracy on validation images (99%).
  

### âš™ï¸ Backend

- Initially exposed to a REST API at /predict. But then deployed at Hugging Face (no need of API)

- Accepts an uploaded image (jpg/png) and returns the label (e.g. rock), and the confidence percentage.


### ğŸ’» Frontend (Streamlit)

- Provides a simple interface to upload an image and view predictions.

- It displays: Uploaded image preview, predicted label and confidence and random machine choice of Rock, Paper or Scissors.

  
---
## ğŸ–¼ï¸ Demo
[Try the App!](https://huggingface.co/spaces/radisando/rock-paper-scissor-app)

![portfolio](https://github.com/user-attachments/assets/7e010fd6-74b1-4926-a1e6-3f0c1e0d8f88)


