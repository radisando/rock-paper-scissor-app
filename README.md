<<<<<<< HEAD
# âœŠðŸ–ï¸âœŒï¸ Rock-Paper-Scissor: An AI Hand Gesture Classifier

Rock-Paper-Scissor is a machine learningâ€“powered app that recognizes hand gestures in images and predicts whether they represent rock, paper, or scissors.
It features a FastAPI backend for model inference and a Streamlit frontend for an intuitive web interface.
Everything is fully Dockerized for seamless deployment and local development.

## ðŸš€ Features

ðŸ§  Deep Learning Classification â€” EfficientNet-based model trained to detect rock, paper, or scissors.

ðŸ“¸ Image Upload Interface â€” Upload any image directly from your browser.

âš™ï¸ FastAPI REST API â€” Lightweight backend serving predictions through a /predict endpoint.

ðŸŒ Streamlit Frontend â€” Clean and interactive UI for testing and visualization.

ðŸ³ Dockerized Architecture â€” Easy to run locally or deploy anywhere using Docker.


## ðŸ§© Repository Structure

This project is organized into two components: a backend (FastAPI) and a frontend (Streamlit).

```bash
â””â”€â”€ rock-paper-scissor-app/
    â”œâ”€â”€ rock-paper-scissor_backend/      # FastAPI backend
    â”‚   â”œâ”€â”€ api/                         # API routes
    â”‚   â”‚   â””â”€â”€ main.py    
    â”‚   â”œâ”€â”€ models/                      # Trained model (.keras)
    â”‚   â”œâ”€â”€ rock_paper_scissor/          # Core logic: model loading & utils
    â”‚   â”œâ”€â”€ tests/                       # Unit tests for API
    â”‚   â”œâ”€â”€ Dockerfile                   # Backend Dockerfile
    â”‚   â””â”€â”€ requirements.txt
    â”‚
    â””â”€â”€ rock-paper-scissor_frontend/     # Streamlit app
        â”œâ”€â”€ app.py                       # Frontend entry point
        â”œâ”€â”€ Dockerfile                   # Frontend Dockerfile
        â””â”€â”€ requirements.txt
```

---
## ðŸ§  Technical Overview

### ðŸ“‚ Dataset

- Based on an open dataset of hand gesture images for Rock, Paper, Scissors recognition.

- Images were resized and augmented to improve generalization.

- Dataset split into training, validation, and test sets.

### ðŸ¤– Model

- Built using Keras / TensorFlow with EfficientNet as the base.

- Trained to classify three gesture categories: rock, paper, scissors

- Achieved strong accuracy on validation images (99%).

### âš™ï¸ Backend (FastAPI)

- Exposes a REST API at /predict.

- Accepts an uploaded image (jpg/png) and returns:

{
  "label": "rock",
  "confidence": 0.93,
  "probabilities": {"rock": 0.93, "paper": 0.04, "scissors": 0.03}
}

- Logs activity and handles errors gracefully (invalid file, empty upload, etc


### ðŸ’» Frontend (Streamlit)

- Provides a simple interface to upload an image and view predictions.

- It displays:

    1. Uploaded image preview

    2. Predicted label and confidence

    3. Class probabilities


### ðŸ³ Dockerization

- Both backend and frontend can run independently or together via Docker Compose.

- Backend image runs FastAPI with Uvicorn on port 8000.

- Frontend image runs Streamlit on port 8501.

- Images communicate via local networking in Docker.


  
---
## âš™ï¸ How to Run Locally

### ðŸ§© 1. Run the Backend (API)

```bash
cd rock-paper-scissor_backend
docker build -t rps-backend .
docker run -d -p 8000:8000 --name rps-api rps-backend
```

### ðŸ’¡ 2. Run the Frontend (Streamlit)

```bash
cd rock-paper-scissor_frontend
python -m venv .venv
source .venv/bin/activate  # or .venv\Scripts\activate on Windows
pip install -r requirements.txt
streamlit run app.py
```

- FastAPI backend â†’ [http://localhost:8000]

- Streamlit frontend â†’ [http://localhost:8501]

---
## ðŸ–¼ï¸ Demo

Web Interface (Streamlit):

( tbd ... screenshot image here!)
=======
# âœŠðŸ–ï¸âœŒï¸ Rock-Paper-Scissor: An AI Hand Gesture Classifier

Rock-Paper-Scissor is a machine learningâ€“powered app that recognizes hand gestures in images and predicts whether they represent rock, paper, or scissors.
It features a FastAPI backend for model inference and a Streamlit frontend for an intuitive web interface.
Everything is fully Dockerized for seamless deployment and local development.

# ðŸš€ Features

ðŸ§  Deep Learning Classification â€” EfficientNet-based model trained to detect rock, paper, or scissors.

ðŸ“¸ Image Upload Interface â€” Upload any image directly from your browser.

âš™ï¸ FastAPI REST API â€” Lightweight backend serving predictions through a /predict endpoint.

ðŸŒ Streamlit Frontend â€” Clean and interactive UI for testing and visualization.

ðŸ³ Dockerized Architecture â€” Easy to run locally or deploy anywhere using Docker.

# ðŸ§© Repository Structure

This project is organized into two components: a backend (FastAPI) and a frontend (Streamlit).

rock-paper-scissor-app/
â”œâ”€â”€ rock-paper-scissor_backend/      # FastAPI backend
â”‚   â”œâ”€â”€ api/                         # API routes
â”‚   â”‚   â””â”€â”€ main.py
â”‚   â”œâ”€â”€ models/                      # Trained model (.keras)
â”‚   â”œâ”€â”€ rock_paper_scissor/          # Core logic: model loading & utils
â”‚   â”œâ”€â”€ tests/                       # Unit tests for API
â”‚   â”œâ”€â”€ Dockerfile                   # Backend Dockerfile
â”‚   â””â”€â”€ requirements.txt
â”‚
â””â”€â”€ rock-paper-scissor_frontend/     # Streamlit app
    â”œâ”€â”€ app.py                       # Frontend entry point
    â”œâ”€â”€ Dockerfile                   # Frontend Dockerfile
    â””â”€â”€ requirements.txt

# ðŸ§  Technical Overview

## ðŸ“‚ Dataset

- Based on an open dataset of hand gesture images for Rock, Paper, Scissors recognition.

- Images were resized and augmented to improve generalization.

- Dataset split into training, validation, and test sets.

## ðŸ¤– Model

- Built using Keras / TensorFlow with EfficientNet as the base.

- Trained to classify three gesture categories: rock, paper, scissors

- Achieved strong accuracy on validation images (99%).

## âš™ï¸ Backend (FastAPI)

- Exposes a REST API at /predict.

- Accepts an uploaded image (jpg/png) and returns:

{
  "label": "rock",
  "confidence": 0.93,
  "probabilities": {"rock": 0.93, "paper": 0.04, "scissors": 0.03}
}

- Logs activity and handles errors gracefully (invalid file, empty upload, etc.).

## ðŸ’» Frontend (Streamlit)

- Provides a simple interface to upload an image and view predictions.

- It displays:

(1) Uploaded image preview

(2) Predicted label and confidence

(3) Class probabilities

## ðŸ³ Dockerization

- Both backend and frontend can run independently or together via Docker Compose.

- Backend image runs FastAPI with Uvicorn on port 8000.

- Frontend image runs Streamlit on port 8501.

- Images communicate via local networking in Docker.

# âš™ï¸ How to Run Locally

### ðŸ§© 1. Run the Backend (API)
cd rock-paper-scissor_backend
docker build -t rps-backend .
docker run -d -p 8000:8000 --name rps-api rps-backend


API available at: http://localhost:8000

### ðŸ’¡ 2. Run the Frontend (Streamlit)
cd rock-paper-scissor_frontend
python -m venv .venv
source .venv/bin/activate  # or .venv\Scripts\activate on Windows
pip install -r requirements.txt
streamlit run app.py


Frontend available at: http://localhost:8501

### ðŸ³ 3. (Optional) Run Both via Docker Compose

In the project root (rock-paper-scissor-app/):

docker compose up --build


This will start:

FastAPI backend â†’ http://localhost:8000

Streamlit frontend â†’ http://localhost:8501


# ðŸ–¼ï¸ Demo

Web Interface (Streamlit):

( tbd ... screenshot image here!)
>>>>>>> 0155356 (Final app available)
